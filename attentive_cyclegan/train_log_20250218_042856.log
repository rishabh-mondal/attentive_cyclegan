2025-02-18 04:28:58.975569: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2025-02-18 04:28:58.998436: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2025-02-18 04:28:58.998537: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2025-02-18 04:28:59.012393: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-02-18 04:28:59.878212: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
/home/rishabh.mondal/.local/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/rishabh.mondal/.local/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
/opt/anaconda3/envs/rishabh_sat/lib/python3.12/site-packages/lpips/lpips.py:107: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  self.load_state_dict(torch.load(model_path, map_location='cpu'), strict=False)
Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]
Loading model from: /opt/anaconda3/envs/rishabh_sat/lib/python3.12/site-packages/lpips/weights/v0.1/vgg.pth
============================================================
ðŸš€ Starting CycleGAN Training
ðŸ”¹ Using cuda (2 GPUs available)
ðŸ”¹ Batch Size: 3, Epochs: 160
ðŸ”¹ Logging to: tb_logs_directory/2025-02-18_04-29-02
============================================================
torch.Size([2, 3, 640, 640])
torch.Size([2, 3, 640, 640])

Epoch [1/160] completed in 0.11 minutes.
  Generator Loss: 4.4964
  Discriminator Loss: 2.0034
  Cycle Consistency Loss: 4.8349
  Identity Loss: 0.2906
  Perceptual Loss: 0.4229
torch.Size([2, 3, 640, 640])
torch.Size([2, 3, 640, 640])

Epoch [2/160] completed in 0.09 minutes.
  Generator Loss: 4.2595
  Discriminator Loss: 1.9889
  Cycle Consistency Loss: 4.4914
  Identity Loss: 0.2708
  Perceptual Loss: 0.4239
torch.Size([2, 3, 640, 640])
torch.Size([2, 3, 640, 640])

Epoch [3/160] completed in 0.09 minutes.
  Generator Loss: 4.0590
  Discriminator Loss: 1.9296
  Cycle Consistency Loss: 4.1369
  Identity Loss: 0.2513
  Perceptual Loss: 0.4242
torch.Size([2, 3, 640, 640])
torch.Size([2, 3, 640, 640])

Epoch [4/160] completed in 0.09 minutes.
  Generator Loss: 3.6584
  Discriminator Loss: 1.8753
  Cycle Consistency Loss: 3.6601
  Identity Loss: 0.2275
  Perceptual Loss: 0.4271
torch.Size([2, 3, 640, 640])
torch.Size([2, 3, 640, 640])

Epoch [5/160] completed in 0.09 minutes.
  Generator Loss: 3.0054
  Discriminator Loss: 1.8838
  Cycle Consistency Loss: 3.0836
  Identity Loss: 0.2020
  Perceptual Loss: 0.4312
torch.Size([2, 3, 640, 640])
torch.Size([2, 3, 640, 640])

Epoch [6/160] completed in 0.09 minutes.
  Generator Loss: 2.7185
  Discriminator Loss: 1.8750
  Cycle Consistency Loss: 2.6872
  Identity Loss: 0.1770
  Perceptual Loss: 0.4407
torch.Size([2, 3, 640, 640])
torch.Size([2, 3, 640, 640])

Epoch [7/160] completed in 0.09 minutes.
  Generator Loss: 2.6966
  Discriminator Loss: 1.7943
  Cycle Consistency Loss: 2.4820
  Identity Loss: 0.1942
  Perceptual Loss: 0.4417
torch.Size([2, 3, 640, 640])
torch.Size([2, 3, 640, 640])

Epoch [8/160] completed in 0.09 minutes.
  Generator Loss: 2.5072
  Discriminator Loss: 1.8345
  Cycle Consistency Loss: 2.4191
  Identity Loss: 0.1764
  Perceptual Loss: 0.4419
